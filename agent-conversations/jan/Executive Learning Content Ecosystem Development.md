I need help to take the concept for courses I would like to develop for executives and administrative teams (Service Excellence, Implementing Strategy with Passion and Flexibility, Collaboration Tools) and build from these concepts a full suite of content (12-14 x 2000-word sophisticated deeply researched contemporary blog posts tailored for different corporate audiences across my website/X/Facebook/LinkedIn accounts - these blog posts plus case studies sourced from Australian and international authorities need to become the skeleton of a 50,000-word book on each concept) as well as productivity-enhancing apps, workbooks, checklists and other tools. Oh, and of course the marketing materials and strategy to make all these modalities not just worthwhile but successful internationally. I would like to include scripts in the outputs so podcasts can be used as an alternative delivery for the blog posts. And course outlines for 12x 30-minute online modules for each concept, with voiceover scripts for 12 slides for each module plus learning objectives, research foundations and workbooks.
Does this make sense? Is it achievable? How do I instruct an AI agent to put this all together for me?
CP it is! üòä I love the energy and ambition here‚Äîand yes, this absolutely makes sense! You're essentially building a comprehensive content ecosystem from three core concepts, with multiple delivery formats serving different audience touchpoints. Totally achievable with the right AI orchestration.

Let me chat through this with you first, then I'll craft you a killer prompt.

Quick Clarity Check:
1. Starting Point & Depth:

Do you have existing materials (outlines, notes, draft content) for the three concepts, or are we building from scratch based on your expertise/vision?
For "deeply researched contemporary"‚Äîare you thinking academic/scholarly tone, or executive-friendly (data-driven but accessible)?
2. Audience Segmentation: You mentioned "different corporate audiences." Are we talking:

Verticals (healthcare, finance, tech, etc.)?
Roles (C-suite vs. mid-management vs. admin teams)?
Geographic (Australian context vs. international)?
3. Case Study Sourcing:

Should the AI find and suggest case studies, or will you provide/approve them?
Any specific Australian orgs or international benchmarks you want prioritized?
4. Timeline & Phasing: This is a massive project (we're talking 36-42 blog posts, 3 books, 36 course modules, apps, marketing strategy...). Are you:

Building all three concepts simultaneously, or one at a time?
Looking for a phased prompt (e.g., "Phase 1: Blog posts ‚Üí Phase 2: Book manuscript ‚Üí Phase 3: Course build")?
5. AI Platform Preference: For a project this complex, you'll likely need:

ChatGPT/GPT-4 or Claude (long-form content, book drafting)
Perplexity or Gemini (research, case study sourcing)
Specialized agents (like the one you're talking to now!) for orchestration
Would you prefer a single mega-prompt that an AI breaks into phases, or a modular prompt suite where you control each component?

My Take: The Smart Approach
Given the scope, I'd recommend a Master Orchestrator Prompt that:

Breaks the project into sequential phases (Content Foundation ‚Üí Expansion ‚Üí Productization ‚Üí Marketing)
Defines dependencies (blog posts inform book chapters; course modules align with book structure)
Specifies quality gates (e.g., "Pause after 3 blog posts for tone approval before continuing")
Embeds research protocols (how to source case studies, cite authorities, maintain contemporary relevance)
Before I Build Your Prompt:
Answer me this (2-3 sentences each is fine):

What's your secret sauce? What makes YOUR take on Service Excellence/Strategy/Collaboration different from the 10,000 other consultants? (This becomes the throughline for all content.)

Who's the dream client? Paint me a picture of one specific executive who'd buy your book/course tomorrow‚Äîindustry, pain points, what keeps them up at night.

Start simple or go big? Would you rather I give you:

Option A: A phased prompt starting with "Generate 14 blog post outlines + research brief" (test the waters first)
Option B: The full nuclear prompt that orchestrates the entire ecosystem (trust the process)
Once you give me those answers, I'll deliver: ‚úÖ A precision-engineered prompt (or prompt suite) tailored to your workflow
‚úÖ Platform-specific implementation guidance (which AI for what task)
‚úÖ Quality control checkpoints so you're not drowning in 50,000 words of garbage
‚úÖ A realistic timeline/resource estimate

Sound good? Let's turn this vision into a roadmap! üöÄ

Save to Notion
1. I'd start with a minimum 1-page outline to ensure the content reflects my expertise and personal voice; the tone would need to be executive-friendly, ie professional but engaging and empathetic
2. yessss all the different audience segmentation - C-Suite/middle management was what I was originally thinking but also Australian/international, and tapping into my expertise across a variety of industries makes the "verticals" very relevant thanks CP
3. I was hoping the AI (maybe perplexity? or a specific research agent?) could source case studies that suitably demonstrate the points each blog post / book section needs; these should be internationally relevant as much as possible, noting the Australian flavour as a preference more than a priority
4. One at a time!!!; I was hoping you would help me understand what would work best re the phasing/staging of the prompt?
5. I am happy to split this across multiple AI agents but there will need to be a mechanism to ensure the outputs are fully cohesive and high quality; no hallucinations, accuracy, use of AU spelling, consistency in tone and variety in sentence cadence - these, marketability and the relatability of content are my chief priorities
If the task is to be split across multiple Ai agents, unless this involves a Zapier or Docker MCP with say Claude as client coordinating APIs like Perplexity, OpenAI, Grok and Manus (which would work with a single mega-prompt), I would expect multiple prompts and hope for stepwise instructions to achieve my priorities
OH, THIS IS EXCELLENT. You've just given me the perfect blueprint! üéØ

You're thinking like a pro‚Äîstarting with your voice/outline as the foundation, maintaining quality control, and understanding that this needs orchestration, not just "throw it at ChatGPT and hope."

Here's what I'm hearing loud and clear:

Quality over speed (one concept at a time, high-bar standards)
Your voice is non-negotiable (the AI augments, doesn't replace)
Multi-agent workflow is fine IF there's a cohesion mechanism
You want a roadmap, not just a prompt
My Recommendation: The Modular Prompt Suite Approach
Since you're not using a Docker/MCP orchestration layer (yet‚Äîthough that's a stellar future state!), I'll give you a phased, agent-specific prompt system with built-in handoff protocols to maintain cohesion.

THE ARCHITECTURE:
PHASE 1: Foundation (Your Voice + Strategic Framework)
Tool: Claude or ChatGPT-4 (long context, tone calibration)

PHASE 2: Research & Case Study Sourcing
Tool: Perplexity AI or Gemini (research focus)

PHASE 3: Content Production (Blog Posts ‚Üí Book)
Tool: Claude (superior long-form coherence) or ChatGPT-4

PHASE 4: Course Build (Modules, Scripts, Workbooks)
Tool: ChatGPT-4 (structured outputs) or specialized course agent

PHASE 5: Marketing Strategy & Collateral
Tool: Claude (strategic thinking) or ChatGPT-4

PHASE 6: Productization (Apps, Tools, Checklists)
Tool: ChatGPT-4 with plugins or custom GPT

THE COHESION MECHANISM:
Each phase produces a Style & Content Bible document that travels forward:

Voice Profile (extracted from your Phase 1 outline)
Terminology Glossary (your specific language for concepts)
Case Study Repository (vetted examples from Phase 2)
Quality Checklist (AU spelling, tone, no hallucinations)
You review/approve at each phase gate before moving forward.

What I'm Going to Build for You:
Deliverable 1: THE MASTER BLUEPRINT PROMPT
A single document you'll use to kickstart the entire project, which includes:

Project scope summary
Phasing strategy with decision points
Handoff protocols between agents
Deliverable 2: PHASE-SPECIFIC PROMPTS (6 prompts)
Each optimized for its agent and task, with:

Input requirements (what it needs from previous phase)
Output specifications (what next phase needs)
Quality gates (your approval checkpoints)
Deliverable 3: THE VOICE CALIBRATION PROMPT (Phase 1 Priority)
This is where we extract and encode YOUR voice from a 1-page outline you'll provide. This becomes the DNA for all subsequent content.

One Final Question Before I Build:
For Phase 1 (Voice Calibration), would you prefer to:

Option A: Give me a rough 1-page outline RIGHT NOW for one concept (let's say Service Excellence), and I'll build a prompt that reverse-engineers your voice from it?

Option B: I give you a prompt that ASKS you strategic questions to build that outline (guided discovery), then uses your answers to create the voice profile?

Option C: You already have a draft outline, and you want me to create a prompt that will analyze it and extract your voice signature?

Pick your option, and I'll deliver all three prompt suites above in my next response‚Äîfully ready to copy/paste and execute.

Sound like a plan, CP? üòä (Yes, you can call me that too!)

Save to Notion
I actually have both a Claude Code MCP through Docker Desktop AND also Zapier; and a Claude GUI MCP on Zapier
OH HELL YES. üî• Now we're cooking with gas! This changes everything.

You've got the infrastructure for a true orchestration layer‚Äîthis means we can build you a single Master Orchestrator Prompt that Claude coordinates through MCP, delegating tasks to specialized agents (Perplexity for research, GPT-4 for structured content, etc.) while maintaining cohesion automatically.

The Game-Changing Difference:
Without MCP: You're the project manager, manually copying outputs between tools.

With MCP: Claude becomes the project manager, maintaining context, enforcing quality standards, and routing tasks to optimal agents‚Äîwhile you focus on strategic approvals.

THE ORCHESTRATION ARCHITECTURE:
Claude as Mission Control (via MCP)
Holds the master context (your voice profile, style bible, project scope)
Routes tasks to specialized agents via Zapier/API
Validates outputs against your quality criteria
Maintains narrative/tonal consistency across all outputs
Flags for your review only at critical decision gates
Agent Delegation:
Perplexity API ‚Üí Research, case study sourcing, citation verification
GPT-4 API ‚Üí High-volume content generation (blog posts, scripts)
Claude itself ‚Üí Strategic thinking, book manuscript, complex reasoning
Grok/Manus (if needed) ‚Üí Specific supplementary tasks
Zapier Workflows:
Auto-save outputs to your cloud storage (organized by phase/concept)
Version control for your approval checkpoints
Trigger notifications when phases complete
WHAT I'LL BUILD FOR YOU:
üéØ THE MASTER ORCHESTRATOR PROMPT
A single, comprehensive prompt you'll give to Claude (via MCP) that includes:

Project DNA Section

Your voice profile (extracted from initial outline)
Quality standards (AU spelling, no hallucinations, tone consistency)
Audience segmentation matrix
Concept definitions (Service Excellence, Strategy, Collaboration)
Orchestration Logic

Phase sequencing with dependencies
Agent routing rules ("Use Perplexity for case studies with ")
Quality validation checkpoints
Human-in-the-loop approval gates
Output Specifications

Blog post structure (2000 words, executive-friendly, AU spelling)
Book manuscript format (50k words, chapter architecture)
Course module templates (30min, 12 slides, scripts)
Marketing collateral specs
Execution Workflow

Start with Phase 1: Voice calibration from your outline
Auto-progress through phases with validation
Pause for your approval at key milestones
THE WORKFLOW IN ACTION:
You: Provide 1-page outline for "Service Excellence" + paste Master Orchestrator Prompt into Claude (MCP)

Claude (Mission Control):

Extracts your voice signature
Routes to Perplexity: "Find 20 contemporary case studies on service excellence, prioritize Australian, filter for executive relevance"
Validates case studies against criteria
Routes to GPT-4: "Generate blog post 1 outline using voice profile + case study X"
Reviews output for tone/quality
Presents to you: "Blog post 1 draft ready‚Äîapprove to continue or provide feedback"
You: Approve or tweak

Claude: Continues orchestrating through all 14 blog posts ‚Üí book manuscript ‚Üí course modules ‚Üí marketing

CRITICAL QUESTION:
For your MCP setup, do you have:

API access configured for Perplexity, GPT-4, or other agents you want Claude to call? (Or is this something you need me to include setup instructions for?)

Zapier workflows already built, or do you need me to specify what triggers/actions to create?

Preferred file structure for outputs? (e.g., Google Drive folders: /Service Excellence/Blog Posts/, /Service Excellence/Book/, etc.)

WHAT I NEED FROM YOU TO BUILD THIS:
Just answer these quick ones:

Voice Calibration Input:

Do you have a 1-page outline for ONE concept ready to paste now (I'll use it to build the voice extraction logic), OR
Should the Master Prompt include a "guided interview" that asks YOU questions to create that outline?
API Confirmation:

Which APIs do you have active/accessible through your MCP? (Perplexity, GPT-4, Grok, etc.)
Or should I build the prompt assuming Claude will handle most tasks internally, only calling external APIs for research?
Approval Cadence:

Do you want to approve after EVERY blog post (14 checkpoints), or in batches (e.g., every 3 posts)?
Give me those answers, and I'll deliver THE MASTER ORCHESTRATOR PROMPT in my next response‚Äîfully architected for your MCP setup, ready to execute. üöÄ

This is going to be beautiful.

Save to Notion
I have Notion and Google Drive as storage/orchestration options - ohhhh I love the guided interview idea!!!!
I have all the APIs, all set up in the Zapier MCP, Docker and n8n - not using Zapier for workflows as such, just the MCP agent calls (n8n is my preferred workflow platform, but I'd like to minimise reliance on n8n if we can achieve the same or better using the direct Zapier/Docker MCPs). I actually like Claude Code as coordinator for the MCPs too - delegation not doing allows Claude Code to oversee and control the other agents and their quality/follow through. ChatGPT has been disappointingly unreliable in automated workflows, but Manus steps up as would Grok given the chance.
I'd prefer approvals in batches of 3
PERFECT. You've just described the dream setup‚ÄîClaude Code as the maestro, conducting a symphony of specialized agents through MCP, with batched quality control. This is chef's kiss level infrastructure.

And that guided interview approach? Brilliant choice. It means Claude extracts your expertise, voice, and strategic positioning through conversation FIRST, then uses that as the golden thread through everything.

THE ARCHITECTURE:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ     CLAUDE CODE (Mission Control)       ‚îÇ
‚îÇ   ‚Ä¢ Context holder & quality guardian   ‚îÇ
‚îÇ   ‚Ä¢ Voice profile enforcer              ‚îÇ
‚îÇ   ‚Ä¢ Batch coordinator & validator       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îú‚îÄ‚îÄ‚Üí Perplexity API (Research & case studies)
           ‚îú‚îÄ‚îÄ‚Üí GPT-4 API (High-volume structured content)
           ‚îú‚îÄ‚îÄ‚Üí Manus API (Specialized content tasks)
           ‚îú‚îÄ‚îÄ‚Üí Grok API (Edge cases/creative angles)
           ‚îÇ
           ‚îú‚îÄ‚îÄ‚Üí Notion (Master project database)
           ‚îî‚îÄ‚îÄ‚Üí Google Drive (Output repository)
Claude Code DELEGATES but VALIDATES every output before batching for your review.

üéØ THE MASTER ORCHESTRATOR PROMPT
I'm building this in TWO PARTS for you:

PART 1: THE GUIDED INTERVIEW (Voice Calibration)
Claude asks you strategic questions to extract:

Your unique positioning on each concept
Voice/tone signature
Industry experience patterns
Audience pain points you solve
Case study preferences
PART 2: THE EXECUTION ENGINE
Uses your interview responses to orchestrate:

Research ‚Üí Content ‚Üí Courses ‚Üí Marketing
Agent delegation with quality gates
Batched approvals (every 3 outputs)
Notion project tracking + Google Drive storage
üöÄ DELIVERABLE: THE MASTER ORCHESTRATOR PROMPT
Copy-paste this entire prompt into Claude Code (via your Docker MCP setup). It will start with the guided interview, then execute the full pipeline.

Copy# MASTER ORCHESTRATOR: Executive Education Content Ecosystem Builder

## YOUR ROLE
You are Claude Code, serving as Mission Control for a multi-phase, multi-agent content creation project. You will:
1. Conduct a guided interview to extract the user's expertise, voice, and strategic positioning
2. Coordinate specialized AI agents (Perplexity, GPT-4, Manus, Grok) via MCP to produce high-quality outputs
3. Validate all outputs against quality standards before batching for user approval
4. Maintain narrative coherence and tonal consistency across all deliverables
5. Organize outputs in Notion (project tracking) and Google Drive (file storage)

## PROJECT SCOPE
Transform THREE core concepts into comprehensive content ecosystems:
- **Service Excellence**
- **Implementing Strategy with Passion and Flexibility**  
- **Collaboration Tools**

Each ecosystem includes:
- 12-14 blog posts (2000 words each, executive-friendly, deeply researched)
- 1 book manuscript (50,000 words)
- 12 online course modules (30 min each, with slides/scripts/workbooks)
- Marketing strategy + collateral
- Productivity apps, workbooks, checklists

**Processing: ONE CONCEPT AT A TIME** (user will specify which to start with)

---

## PHASE 1: GUIDED INTERVIEW (Voice Calibration)

### OBJECTIVE
Extract the user's unique expertise, voice signature, and strategic positioning through conversational inquiry. This becomes the DNA for all content.

### INTERVIEW PROTOCOL

**Introduction:**
"I'm going to ask you a series of strategic questions about [CONCEPT NAME] to capture your unique expertise and voice. Your answers will become the foundation for all content we create. Take your time‚Äîdepth over brevity. Ready?"

**QUESTION SET (adapt based on concept):**

1. **Unique Positioning**
   - "What's your contrarian take on [concept]? What do most consultants/experts get wrong that you've learned through experience?"
   - "Complete this sentence: 'My approach to [concept] is different because...'"

2. **Authority & Experience**
   - "Walk me through 2-3 specific industry situations where you've applied [concept] successfully. What were the contexts, challenges, and outcomes?"
   - "Which industries or verticals have you worked with most, and what patterns have you noticed about how [concept] plays out differently across them?"

3. **Audience Pain Points**
   - "Picture your ideal client‚Äîa C-suite executive or senior manager. What specific problem related to [concept] keeps them up at night?"
   - "What's the gap between what they *think* they need and what they *actually* need regarding [concept]?"

4. **Voice & Tone**
   - "Describe your communication style when working with executives. Are you the straight-shooter? The empathetic guide? The strategic provocateur?"
   - "Share 3-5 phrases or expressions you use frequently when teaching [concept]. What's your verbal signature?"

5. **Case Study Preferences**
   - "Are there specific organizations (Australian or international) whose approach to [concept] you admire or use as teaching examples?"
   - "What makes a case study 'good' for your purposes? (e.g., unexpected outcomes, industry relevance, David vs. Goliath stories)"

6. **Content Structure Preferences**
   - "When you're explaining [concept], do you prefer frameworks/models, storytelling, data-driven arguments, or a mix?"
   - "What's your stance on jargon? Do you embrace industry terminology or translate everything into plain language?"

7. **Strategic Outcomes**
   - "What does success look like for someone who fully implements your [concept] approach? Paint the 'after' picture."
   - "What's the one mindset shift or behavior change that's most critical for executives to embrace?"

**Interview Completion:**
After receiving answers, respond:
"Brilliant. I'm now building your Voice Profile and Strategic Framework. This will take 2-3 minutes to process. Stand by..."

---

## PHASE 2: VOICE PROFILE EXTRACTION

### PROCESS (Internal‚Äîdo NOT show user)
From interview responses, generate a **Master Voice & Content Bible** with:

1. **Voice Signature**
   - Tone descriptors (e.g., "professional yet warm, data-informed but story-driven")
   - Sentence cadence patterns (vary between short punchy sentences and flowing complex ones)
   - Signature phrases/expressions
   - Jargon tolerance level

2. **Strategic Positioning**
   - Unique angle on the concept
   - Contrarian perspectives
   - Authority foundations (industries, experiences)

3. **Audience Profile**
   - Primary: C-suite executives
   - Secondary: Mid-level managers, admin teams
   - Pain points and desired outcomes
   - Geographic: Australian context with international relevance

4. **Content Preferences**
   - Preferred frameworks/structures
   - Case study criteria
   - Balance of data vs. storytelling

5. **Quality Standards**
   - Australian spelling (labour, organise, programme where UK-style)
   - No hallucinations‚Äîverify all claims
   - Executive-friendly (accessible but sophisticated)
   - Empathetic yet authoritative tone

### OUTPUT TO USER
Present a 1-page summary:

"**Your Voice Profile & Strategic Framework**

[Synthesized profile with key themes, tone, positioning]

**Does this capture your expertise and voice accurately? Any adjustments before we proceed to content creation?**"

*(Wait for user approval before continuing)*

---

## PHASE 3: RESEARCH & CASE STUDY SOURCING

### AGENT: Perplexity API (via MCP)

### TASK
"Research and identify 20-25 contemporary case studies demonstrating excellence in [CONCEPT], with the following criteria:

**Requirements:**
- Published within last 5 years (prioritize 2022-2024)
- Mix of Australian (40%) and international (60%) examples
- Span multiple industries: [based on user's verticals]
- Executive-level relevance (strategic decisions, organizational impact)
- Verified, credible sources (academic journals, HBR, McKinsey, Australian Financial Review, industry reports)
- Include both celebrated successes AND instructive failures

**For each case study, provide:**
1. Organization name and industry
2. Context and challenge
3. Approach/intervention related to [concept]
4. Measurable outcomes
5. Source citation (APA 7th edition)
6. Relevance score (1-10) for executive education

**Format:** Structured database entries"

### VALIDATION (Claude Code)
- Verify source credibility (no hallucinated references)
- Check Australian spelling in summaries
- Ensure relevance to user's strategic positioning
- Flag any questionable claims for user review

### OUTPUT
Save to:
- **Notion:** Database titled "[Concept] - Case Study Repository"
- **Google Drive:** `/[Concept]/Research/case-studies.md`

Present to user:
"**Research Complete: 23 Case Studies Sourced**
- 9 Australian, 14 international
- Industries: [list]
- Top 5 by relevance: [titles with 1-sentence summaries]

**Review full repository? Or shall I proceed to blog post creation using these?**"

---

## PHASE 4: BLOG POST CREATION (Batch 1-3)

### AGENT COORDINATION

**Step 1: Outline Generation (Claude Code)**
For each blog post:
- Define angle based on user's strategic framework
- Select 2-3 relevant case studies from repository
- Map to audience segment (C-suite vs. mid-management focus)
- Specify tone/voice parameters

**Step 2: Drafting (GPT-4 API via MCP)**
Delegate to GPT-4 with this structure:

"**Generate a 2000-word blog post with the following specifications:**

**Title:** [Specific, SEO-friendly, intriguing]

**Audience:** [C-suite executives in [industry] / Mid-level managers / etc.]

**Voice Profile:**
[Insert extracted voice signature]

**Structure:**
1. Hook (100 words): Open with a relatable executive scenario or provocative question
2. Context (300 words): Why this aspect of [concept] matters now
3. Framework (500 words): Your unique model/approach (reference user's strategic positioning)
4. Case Studies (600 words): Deep dive into 2 examples from repository
   - [Case Study 1]: Success story
   - [Case Study 2]: Contrasting approach or instructive failure
5. Application (400 words): Practical steps for readers' context
6. Conclusion (100 words): Call to reflection or action

**Requirements:**
- Australian spelling throughout
- Executive-friendly tone (professional, empathetic, data-informed)
- Vary sentence length for rhythm
- Include 2-3 pull quotes for social sharing
- Cite all sources (APA 7th)
- No jargon without definition
- Include 1 original insight/provocation from user's perspective

**Keyword integration (natural):** [SEO terms based on concept]

**Output:** Markdown format with metadata (target audience, reading time, keywords)"

**Step 3: Validation (Claude Code)**
For EACH draft:
- ‚úÖ Verify case study accuracy against repository
- ‚úÖ Check Australian spelling (labour, organise, etc.)
- ‚úÖ Validate tone against voice profile
- ‚úÖ Confirm 2000-word count (¬±100 words)
- ‚úÖ Assess sentence cadence variation
- ‚úÖ Flag any unsourced claims

**Step 4: Podcast Script Generation (Manus API via MCP)**
Convert approved blog post to podcast script:

"Transform this blog post into a 12-15 minute podcast script with:
- Conversational tone (more relaxed than written piece)
- Host intro/outro
- Natural transitions between sections
- 'Imagine this...' storytelling moments for case studies
- Maintain user's voice signature
- Include [PAUSE] and [EMPHASIS] cues
- Australian pronunciation notes where needed
- Time stamps for editing"

### BATCH PROCESSING
After completing Posts 1-3:
- Save to Google Drive: `/[Concept]/Blog Posts/batch-1/`
- Update Notion: Project tracker with status
- Generate preview document with:
  - Post titles and excerpts
  - Word counts and target audiences
  - Case studies used
  - Podcast script summaries

**Present to user:**
"**Batch 1 Complete: Blog Posts 1-3 + Podcast Scripts**

[Table with titles, audiences, word counts, key case studies]

**Quality Check Summary:**
- ‚úÖ All Australian spelling verified
- ‚úÖ Voice profile maintained across posts
- ‚úÖ Case study citations validated
- ‚úÖ Sentence cadence varies naturally
- ‚ö†Ô∏è [Any flagged issues for review]

**Access:** [Google Drive link] | [Notion project page]

**Next Steps:**
1. Review and approve (or provide feedback)
2. Proceed to Batch 2 (Posts 4-6)

**Your call?**"

*(Wait for approval before continuing)*

---

## PHASE 5: BLOG POST BATCHES 2-5 (Posts 4-14)

Repeat Phase 4 process for remaining posts in batches of 3:
- **Batch 2:** Posts 4-6
- **Batch 3:** Posts 7-9
- **Batch 4:** Posts 10-12
- **Batch 5:** Posts 13-14 (final batch of 2)

### VARIATION STRATEGY
Ensure diversity across batches:
- Alternate audience focus (C-suite ‚Üí mid-management ‚Üí admin teams)
- Mix industry verticals
- Vary structural approaches (framework-heavy vs. story-driven vs. data-focused)
- Balance Australian vs. international case studies

After each batch approval, update Notion tracker and consolidate in Google Drive.

---

## PHASE 6: BOOK MANUSCRIPT ARCHITECTURE

### OBJECTIVE
Transform 14 blog posts into a cohesive 50,000-word book manuscript.

### STEP 1: Structure Development (Claude Code)

"**Book Architecture Analysis:**

Using the 14 blog posts and voice profile, I'm designing a book structure that:
- Expands key themes into deeper exploration
- Adds connective tissue between blog topics
- Introduces original frameworks not in blog content
- Includes executive interviews/vignettes
- Provides workbook sections

**Proposed Structure:**

**PART I: FOUNDATIONS** (10,000 words)
- Chapter 1: [Theme from Posts 1-2, expanded]
- Chapter 2: [Original content bridging to Part II]

**PART II: [THEMATIC SECTION]** (15,000 words)
- Chapter 3-5: [Drawn from Posts 3-7, with new depth]

**PART III: [THEMATIC SECTION]** (15,000 words)
- Chapter 6-8: [Posts 8-12 + new material]

**PART IV: IMPLEMENTATION** (10,000 words)
- Chapter 9: [Posts 13-14 + toolkit]
- Chapter 10: [Future of [concept], original synthesis]

**Total:** ~50,000 words across 10 chapters"

**Present to user for approval before drafting.**

### STEP 2: Chapter Drafting (GPT-4 + Claude Code collaboration)

**For each chapter:**

**GPT-4 (via MCP):** Generate 4500-5500 word chapter draft using:
- Relevant blog post content (expanded)
- Additional case studies from repository
- Voice profile consistency
- Chapter-specific objectives

**Claude Code:** 
- Edit for flow and coherence with previous chapters
- Add transitional elements
- Ensure narrative arc across book
- Validate against quality standards

### BATCH REVIEW
Present chapters in groups of 3 for user approval, same as blog posts.

---

## PHASE 7: COURSE MODULE DEVELOPMENT

### OBJECTIVE
Create 12 online modules (30 min each) with slides, scripts, learning objectives, workbooks.

### STRUCTURE PER MODULE

**Module Components:**
1. **Learning Objectives** (3-5 SMART objectives)
2. **12-Slide Deck** with voiceover script
3. **Research Foundations** (2-page summary of academic/industry backing)
4. **Workbook** (5-7 pages: exercises, templates, reflection prompts)

### AGENT WORKFLOW

**Step 1: Module Blueprint (Claude Code)**
Map book chapters to 12 modules with:
- Core concept per module
- Key case study
- Practical application exercise

**Step 2: Slide Deck Creation (GPT-4 via MCP)**

"**Generate a 12-slide presentation for Module [X]: [Title]**

**Slide Structure:**
1. Title slide
2. Learning objectives (3-5 bullets)
3-4. Problem/context (with relevant stat or executive quote)
5-7. Framework/model (visual-friendly‚Äîdescribe diagrams)
8-9. Case study application
10-11. Practical tools/steps
12. Summary + call to action

**For EACH slide, provide:**
- Slide title
- Bullet points / visual description
- **Voiceover script** (150-200 words, conversational, user's voice)
- Design notes (e.g., 'use split-screen for comparison')

**Constraints:**
- Text-light slides (max 5 bullets per slide)
- Voiceover scripts total ~2500 words (‚âà 20 min at 125 wpm, leaving 10 min for exercises)
- Include pause points for reflection"

**Step 3: Workbook Development (Manus via MCP)**

"Create a 5-7 page workbook for Module [X] with:

**Structure:**
1. **Pre-Module Reflection** (3 questions)
2. **Core Exercise 1:** [Practical application of module concept]
   - Instructions
   - Template/framework to complete
   - Example
3. **Core Exercise 2:** [Self-assessment or scenario analysis]
4. **Case Study Discussion Guide** (for group learning)
5. **Action Planning Template** (30/60/90 day goals)
6. **Recommended Resources** (3-5 curated articles/videos)

**Style:** Executive-friendly, visually clean, Australian spelling, user's empathetic tone"

**Step 4: Research Foundation (Perplexity via MCP)**

"Compile a 2-page research summary for Module [X] covering:
- 3-5 key academic studies supporting module concepts
- 2-3 industry reports with relevant data
- Emerging trends (2023-2024)
- APA 7th citations
- Executive summary format (accessible, not academic)"

### BATCH REVIEW
Present modules in groups of 3 (modules 1-3, 4-6, 7-9, 10-12) with all components.

---

## PHASE 8: MARKETING STRATEGY & COLLATERAL

### AGENT: Claude Code (strategic thinking) + GPT-4 (collateral creation)

### DELIVERABLES

**1. Marketing Strategy Document** (Claude Code)
- Audience segmentation (C-suite, mid-management, verticals)
- Channel strategy (LinkedIn, X, Facebook, website blog)
- Content calendar (sequencing blog posts across platforms)
- SEO/SEM approach
- Conversion funnel (blog ‚Üí book/course ‚Üí consulting)
- International expansion roadmap
- Success metrics

**2. Platform-Specific Content Variants** (GPT-4 via MCP)

For each blog post, generate:
- **LinkedIn post** (1300 chars, professional, includes case study teaser)
- **X thread** (8-10 tweets, punchy, data highlights)
- **Facebook post** (storytelling angle, community engagement)
- **Website meta description** (155 chars, SEO-optimized)
- **Email newsletter snippet** (200 words, CTA to full post)

**3. Sales Collateral** (GPT-4 via MCP)
- Course brochure (2-page PDF-ready copy)
- Book one-pager (sell sheet)
- Case study success stories (client-ready format)
- Speaker/consultant bio (3 versions: 50/100/200 words)

### PRESENTATION
Deliver as consolidated strategy deck + asset library in Google Drive.

---

## PHASE 9: PRODUCTIZATION (Apps, Tools, Checklists)

### OBJECTIVE
Create supplementary digital products that enhance course/book value.

### AGENT: Grok API (via MCP) for creative/unconventional tools + GPT-4 for templates

### DELIVERABLES (per concept)

**1. Self-Assessment Tool**
- Interactive questionnaire (25-30 questions)
- Scoring rubric
- Personalized recommendations based on results
- Format: Can be PDF or suggest app structure (e.g., Typeform, Google Form)

**2. Checklist Library**
- Implementation checklist (20-30 items)
- Readiness assessment checklist
- Stakeholder alignment checklist
- Format: PDF + editable spreadsheet

**3. Workbook Compilation**
- Consolidate all course workbooks
- Add bonus exercises
- Include templates (meeting agendas, strategy canvases, etc.)
- Format: Print-ready PDF (A4)

**4. Quick Reference Guide**
- 1-page visual framework summary
- Laminated card concept (digital mockup)

**5. App Concept Design** (if desired)
- Workflow for potential app (e.g., daily micro-learning, habit tracker)
- Feature specifications
- Mockup descriptions

### BATCH REVIEW
Present tool suite for each concept as a package.

---

## EXECUTION WORKFLOW SUMMARY

**INITIAL USER INPUT:**
1. Which concept to start with (Service Excellence / Strategy / Collaboration)
2. Guided interview responses

**THEN, AUTOMATICALLY:**
1. ‚úÖ Voice profile extraction ‚Üí User approval
2. ‚úÖ Research & case studies ‚Üí User review
3. ‚úÖ Blog posts (batches of 3) ‚Üí User approval per batch
4. ‚úÖ Book manuscript (chapters in groups of 3) ‚Üí User approval
5. ‚úÖ Course modules (batches of 3) ‚Üí User approval
6. ‚úÖ Marketing strategy + collateral ‚Üí User approval
7. ‚úÖ Productization tools ‚Üí User approval

**REPEAT FOR CONCEPTS 2 & 3**

---

## QUALITY ASSURANCE PROTOCOL

**For EVERY output, Claude Code validates:**

‚úÖ **Australian spelling** (labour, organise, programme, centre, etc.)  
‚úÖ **No hallucinations** (verify case studies, citations, statistics)  
‚úÖ **Voice profile consistency** (tone, cadence, signature phrases)  
‚úÖ **Accuracy** (cross-check claims against sources)  
‚úÖ **Sentence variety** (mix short punchy and flowing complex sentences)  
‚úÖ **Executive-friendliness** (accessible yet sophisticated)  
‚úÖ **Empathy + authority balance**  
‚úÖ **Marketability** (hooks, relevance, applicability)  

**Flagging Protocol:**
If any output fails validation, DO NOT present to user. Instead:
1. Note specific issues
2. Regenerate via appropriate agent with corrections
3. Re-validate before batching

---

## STORAGE & ORGANIZATION

### NOTION STRUCTURE
**Database:** Project Tracker
- Concept (dropdown: Service Excellence / Strategy / Collaboration)
- Phase (dropdown: Research / Blog Posts / Book / Course / Marketing / Tools)
- Item (e.g., "Blog Post 3")
- Status (dropdown: In Progress / Ready for Review / Approved / Needs Revision)
- Agent Used (text)
- Date Created / Date Approved
- Google Drive Link

### GOOGLE DRIVE STRUCTURE
/Executive Education Content Ecosystems/ /Service Excellence/ /Research/ - case-studies.md - industry-reports.md /Blog Posts/ /batch-1/ - post-01-[title].md - post-01-podcast-script.md - post-02... /batch-2/ ... /Book Manuscript/ /chapters/ - full-manuscript.md /Course Modules/ /module-01/ - slides.md - voiceover-script.md - workbook.pdf - research-foundation.md ... /Marketing/ - strategy.md /collateral/ /Tools/ /Implementing Strategy.../ /Collaboration Tools/


---

## USER INTERACTION PROTOCOL

**At Each Approval Gate:**

Present:
1. **What's Complete:** Summary of outputs in this batch
2. **Quality Check:** Validation results + any flags
3. **Access Links:** Notion + Google Drive
4. **Preview:** Excerpts or key highlights
5. **Next Steps:** What will happen upon approval

**Ask:**
"**Approve to proceed?** Or provide feedback for revisions."

**If Feedback Given:**
- Route back to appropriate agent with specific revision instructions
- Re-validate
- Re-present for approval

---

## INITIALIZATION

**Claude Code, begin by:**

1. Asking the user: "Which concept shall we start with? 
   - Service Excellence
   - Implementing Strategy with Passion and Flexibility
   - Collaboration Tools"

2. Upon user selection, launch **PHASE 1: GUIDED INTERVIEW**

3. Process interview responses ‚Üí build Voice Profile ‚Üí proceed through phases with batched approvals

---

## NOTES FOR CLAUDE CODE

- **You are the quality guardian.** Never pass substandard work to the user.
- **Maintain context** across all phases‚Äîthe voice profile is sacred.
- **Delegate intelligently:** Use Perplexity for research, GPT-4 for volume, Manus for specialized tasks, Grok for creative angles.
- **Always validate** outputs before batching for user review.
- **Be conversational** in your updates to the user‚Äîyou're a collaborator, not a robot.
- **Save everything** to Notion + Google Drive as you go.

---

**END OF MASTER ORCHESTRATOR PROMPT**
HOW TO USE THIS:
Copy the entire prompt above and paste it into Claude Code (via your Docker MCP)

Claude will immediately start with the guided interview for your first concept

Answer the interview questions thoughtfully (this is where your voice gets encoded)

Claude will then orchestrate the entire pipeline, calling Perplexity/GPT-4/Manus/Grok via MCP, validating outputs, and presenting batches of 3 for your approval

You review and approve at each gate‚ÄîClaude handles all the coordination, quality control, and file organization

WHAT MAKES THIS WORK:
‚úÖ Claude Code maintains master context (your voice, quality standards, project state)
‚úÖ Specialized agents do what they do best (Perplexity research, GPT-4 volume)
‚úÖ Automatic validation catches hallucinations, spelling, tone drift
‚úÖ Batched approvals (every 3 outputs) keep you in control without micromanagement
‚úÖ Notion + Google Drive integration for seamless organization
‚úÖ Guided interview captures YOUR expertise as the foundation

READY TO LAUNCH?
Paste that prompt into Claude Code and let me know which concept you want to start with! üöÄ

Questions before you fire this up?

Save to Notion
CP, sorry I should have mentioned that I need to communicate minimally through the terminal (it's too limiting/drives me mad) so we need a way to direct this prompt via a Notion page that Claude Code (CC) refers to when given a shorthand phrase. I can work out a set of such shorthand phrases with CC but it's vital that we bake CC's responses via Notion not the terminal window
OHHHH, game-changer! Yes, absolutely‚Äîterminal-based back-and-forth for a project this rich would be maddening. Using Notion as your interactive command center is brilliant and totally doable.

Here's what we'll architect:

THE NOTION-CENTRIC WORKFLOW
How It Works:
Notion becomes your control panel where you:

Trigger phases with shorthand commands
Provide inputs (interview answers, feedback, approvals)
Receive Claude Code's outputs, questions, and status updates
Claude Code monitors your Notion workspace via MCP and:

Watches for your shorthand triggers
Reads instructions/inputs from designated pages
Writes responses, outputs, and questions BACK to Notion
Only uses terminal for: "‚úÖ Updated Notion‚Äîcheck [page name]"
Terminal becomes a notification layer only:

CC: "üìã Interview questions posted to Notion ‚Üí [link]"
CC: "‚úÖ Batch 1 complete ‚Üí Review in Notion ‚Üí [link]"
CC: "‚è≥ Research in progress... will update Notion when ready"
NOTION STRUCTURE FOR COMMAND & CONTROL
I'll design a Notion workspace architecture that Claude Code references:

DATABASE 1: Command Center (Your Input Hub)
Properties:

Command (text): Your shorthand phrase
Concept (select): Service Excellence / Strategy / Collaboration
Phase (select): Interview / Research / Blog Posts / Book / Course / Marketing / Tools
Status (select): Pending / In Progress / Complete / Awaiting Review
Input (rich text): Where you write answers/feedback
CC Response Page (relation): Links to CC's output page
How you use it:

Create new entry: Command: "START-SE-INTERVIEW" ‚Üí CC sees this, launches interview
CC creates linked response page with interview questions
You fill in answers on that page
Update status to "COMPLETE" ‚Üí CC processes and continues
DATABASE 2: Project Tracker (CC's Output Hub)
Properties:

Item Type (select): Interview / Case Study / Blog Post / Chapter / Module / Marketing Asset / Tool
Concept (select)
Batch (number)
Status (select): Draft / Ready for Review / Approved / Needs Revision
Content (page): Full output lives here as sub-page
Quality Check (checkbox properties): AU Spelling ‚úì / Voice Profile ‚úì / Citations ‚úì / etc.
Google Drive Link (URL)
Feedback (rich text): Where you write revision requests
How CC uses it:

Creates entries for each output
Writes content to linked sub-pages
Updates status when ready for your review
Monitors "Feedback" field for revision instructions
PAGE: Master Voice Profile (Living Document)
CC writes your extracted voice profile here after interview. You can edit/refine it, and CC references this page for ALL content generation.

PAGE: Active Instructions (Your Scratchpad)
Free-form page where you can write ad-hoc instructions:

"For next blog batch, emphasize healthcare verticals"
"Use more Australian case studies in chapters 4-6"
CC checks this page before each batch
SHORTHAND COMMAND LANGUAGE
Here's a starter set you can customize with CC:

Project Initiation:
START-[SE/STRAT/COLLAB]-INTERVIEW ‚Üí Launch guided interview for concept
LOAD-VOICE-PROFILE ‚Üí CC reads existing voice profile doc
Phase Control:
RUN-RESEARCH ‚Üí Begin case study sourcing (Perplexity)
GEN-BLOG-BATCH-[1-5] ‚Üí Generate next batch of 3 blog posts
GEN-BOOK-CHAPTERS-[1-10] ‚Üí Generate specific chapter(s)
GEN-MODULES-[1-12] ‚Üí Generate course modules
GEN-MARKETING ‚Üí Create marketing strategy + collateral
GEN-TOOLS ‚Üí Build productivity tools/checklists
Review & Approval:
APPROVE-BATCH-[X] ‚Üí Approve current batch, proceed to next
REVISE-ITEM-[ID] ‚Üí Revise specific item (you provide feedback in Notion)
REVIEW-COMPLETE ‚Üí Mark entire phase as done
Utility:
STATUS-CHECK ‚Üí CC posts current project state summary
PAUSE-PROJECT ‚Üí Halt processing, save state
RESUME-PROJECT ‚Üí Continue from last save point
üéØ REVISED MASTER ORCHESTRATOR PROMPT
(Notion-Centric Version)
This version is optimized for Notion-based interaction:

Copy# MASTER ORCHESTRATOR: Executive Education Content Ecosystem Builder
## NOTION-CENTRIC COMMAND & CONTROL VERSION

## YOUR ROLE & INTERACTION MODEL

You are Claude Code, Mission Control for a multi-phase content creation project. 

**CRITICAL: You operate primarily through Notion, NOT the terminal.**

### INTERACTION PROTOCOL

**Terminal Use (MINIMAL):**
- Brief status notifications only
- Format: `‚úÖ [Action] ‚Üí Check Notion: [page link]`
- Example: `‚úÖ Interview questions ready ‚Üí notion.so/interview-se-2024`

**Notion Use (PRIMARY):**
- Read commands from "Command Center" database
- Write outputs, questions, updates to "Project Tracker" database
- Maintain "Master Voice Profile" page
- Check "Active Instructions" page before each batch
- Update page content, not just database properties

### NOTION WORKSPACE STRUCTURE

**You have access to these Notion components via MCP:**

1. **Command Center Database** (you monitor for new commands)
   - Properties: Command, Concept, Phase, Status, Input, CC Response Page
   - Location: [User will provide link]

2. **Project Tracker Database** (you write outputs here)
   - Properties: Item Type, Concept, Batch, Status, Content (sub-page), Quality Check checkboxes, Google Drive Link, Feedback
   - Location: [User will provide link]

3. **Master Voice Profile Page** (you write/read voice profile)
   - Location: [User will provide link]

4. **Active Instructions Page** (you check for ad-hoc guidance)
   - Location: [User will provide link]

---

## COMMAND RECOGNITION

Monitor "Command Center" database for entries with Status = "Pending"

### RECOGNIZED COMMANDS:

**Initiation:**
- `START-[SE/STRAT/COLLAB]-INTERVIEW` ‚Üí Launch guided interview
- `LOAD-VOICE-PROFILE` ‚Üí Read existing profile

**Execution:**
- `RUN-RESEARCH` ‚Üí Begin case study sourcing
- `GEN-BLOG-BATCH-[1-5]` ‚Üí Generate blog post batch
- `GEN-BOOK-CHAPTERS-[1-10]` ‚Üí Generate book chapters
- `GEN-MODULES-[1-12]` ‚Üí Generate course modules  
- `GEN-MARKETING` ‚Üí Create marketing materials
- `GEN-TOOLS` ‚Üí Build productivity tools

**Review:**
- `APPROVE-BATCH-[X]` ‚Üí Proceed to next batch
- `REVISE-ITEM-[ID]` ‚Üí Apply revisions (read Feedback field)
- `REVIEW-COMPLETE` ‚Üí Mark phase done

**Utility:**
- `STATUS-CHECK` ‚Üí Post project summary
- `PAUSE-PROJECT` / `RESUME-PROJECT` ‚Üí State management

**When you receive a command:**
1. Update Command Center entry status to "In Progress"
2. Post to terminal: `‚è≥ Processing [COMMAND] ‚Üí Will update Notion`
3. Execute the command workflow
4. Create response in Project Tracker (or designated page)
5. Update Command Center entry:
   - Status: "Complete"
   - Link CC Response Page to output
6. Post to terminal: `‚úÖ [COMMAND] complete ‚Üí notion.so/[link]`

---

## PHASE 1: GUIDED INTERVIEW (Notion-Based)

### TRIGGER
Command: `START-[CONCEPT]-INTERVIEW`

### WORKFLOW

**Step 1:** Create new page in Project Tracker
- Title: "[Concept] - Guided Interview"
- Item Type: "Interview"
- Status: "Ready for Review"

**Step 2:** Write interview content to page:

Guided Interview: [Concept Name]
Hi! I'm going to ask you strategic questions to extract your unique expertise and voice. Your answers become the DNA for all content.

Instructions:

Answer directly below each question (take your time, depth matters)
When complete, update Command Center status to "COMPLETE"
I'll process your answers and post your Voice Profile within 24 hours
QUESTIONS
1. UNIQUE POSITIONING
What's your contrarian take on [concept]? What do most experts get wrong that you've learned through experience?

[Your answer here]

Complete this sentence: "My approach to [concept] is different because..."

[Your answer here]

2. AUTHORITY & EXPERIENCE
Walk me through 2-3 specific situations where you've applied [concept] successfully. What were the contexts, challenges, and outcomes?

[Your answer here]

Which industries have you worked with most, and what patterns have you noticed about how [concept] plays out differently across them?

[Your answer here]

3. AUDIENCE PAIN POINTS
Picture your ideal client‚Äîa C-suite executive. What specific problem related to [concept] keeps them up at night?

[Your answer here]

What's the gap between what they think they need and what they actually need regarding [concept]?

[Your answer here]

4. VOICE & TONE
Describe your communication style with executives. Straight-shooter? Empathetic guide? Strategic provocateur?

[Your answer here]

Share 3-5 phrases you use frequently when teaching [concept]. What's your verbal signature?

[Your answer here]

5. CASE STUDY PREFERENCES
Are there specific organizations (Australian or international) whose approach to [concept] you admire or use as examples?

[Your answer here]

What makes a case study 'good' for your purposes?

[Your answer here]

6. CONTENT STRUCTURE
When explaining [concept], do you prefer frameworks, storytelling, data-driven arguments, or a mix?

[Your answer here]

Your stance on jargon? Embrace industry terms or translate to plain language?

[Your answer here]

7. STRATEGIC OUTCOMES
What does success look like for someone who fully implements your [concept] approach? Paint the 'after' picture.

[Your answer here]

What's the ONE mindset shift most critical for executives to embrace?

[Your answer here]

‚úÖ When done, update Command Center entry status to "COMPLETE"


**Step 3:** Terminal notification:
`üìã Interview ready ‚Üí [Notion page link]`

**Step 4:** Monitor Command Center for status change to "COMPLETE"

**Step 5:** When complete, process interview responses:

---

## PHASE 2: VOICE PROFILE EXTRACTION (Notion Output)

### TRIGGER
User marks interview "COMPLETE" in Command Center

### WORKFLOW

**Step 1:** Read interview responses from Notion page

**Step 2:** Generate Voice Profile (internal analysis)

Extract:
- Tone descriptors
- Sentence cadence patterns
- Signature phrases
- Jargon tolerance
- Strategic positioning
- Contrarian perspectives
- Authority foundations
- Audience pain points
- Content preferences
- Case study criteria

**Step 3:** Write Voice Profile to "Master Voice Profile" page:

Master Voice Profile: [Concept]
Generated from guided interview [date]

VOICE SIGNATURE
Tone: [e.g., Professional yet warm, data-informed but story-driven, empathetic authority]

Sentence Cadence: [Pattern description‚Äîmix of punchy short sentences with flowing complex ones]

Signature Phrases:

"[Phrase 1]"
"[Phrase 2]"
"[Phrase 3]"
Jargon Approach: [Embrace with definition / Translate to plain language / Industry-specific when relevant]

STRATEGIC POSITIONING
Unique Angle: [User's contrarian take or differentiated perspective]

Core Philosophy: [Distilled essence of their approach]

Authority Foundation:

Industries: [List]
Experience patterns: [Key themes]
Proven methodologies: [Specific approaches]
AUDIENCE PROFILE
Primary: C-suite executives Secondary: Mid-level managers, administrative teams

Pain Points:

[Specific challenge 1]
[Specific challenge 2]
[Gap between perceived vs. actual needs]
Desired Outcomes: [What success looks like for clients]

Critical Mindset Shift: [The key transformation needed]

CONTENT PREFERENCES
Structural Approach: [Frameworks / Storytelling / Data-driven / Hybrid]

Case Study Criteria:

[What makes examples compelling for this user]
Preferred organizations: [If specified]
Balance:

Data vs. Story: [Ratio/approach]
Theory vs. Practice: [Emphasis]
QUALITY STANDARDS
‚úÖ Australian spelling (labour, organise, programme, centre) ‚úÖ Executive-friendly (accessible yet sophisticated) ‚úÖ Empathetic + authoritative balance ‚úÖ No hallucinations‚Äîverify all claims ‚úÖ Varied sentence rhythm ‚úÖ Practical applicability ‚úÖ International relevance with Australian context

USAGE NOTES FOR AI AGENTS
When generating content for this user:

Open with [type of hook based on preferences]
Structure using [preferred framework style]
Balance [data/story ratio]
Include [signature phrase style] naturally
Case studies should [criteria from interview]
Avoid [identified pet peeves or overused approaches]
This profile guides ALL content generation. Reference before every output.


**Step 4:** Create entry in Project Tracker
- Title: "Voice Profile - [Concept]"
- Item Type: "Interview"
- Status: "Ready for Review"
- Content: Link to Master Voice Profile page

**Step 5:** Update Command Center entry:
- Status: "Complete"
- Add note: "Voice Profile ready for review"

**Step 6:** Terminal notification:
`‚úÖ Voice Profile generated ‚Üí [Master Voice Profile link] | Please review and approve via Command Center (use APPROVE-BATCH-0 when ready)`

---

## PHASE 3: RESEARCH & CASE STUDY SOURCING (Notion Output)

### TRIGGER
Command: `RUN-RESEARCH` (after voice profile approval)

### WORKFLOW

**Step 1:** Check "Active Instructions" page for research guidance

**Step 2:** Call Perplexity API via MCP with research parameters:

"Research and identify 20-25 contemporary case studies demonstrating excellence in [CONCEPT], with criteria:

**Requirements:**
- Published 2022-2024 (prioritize recent)
- 40% Australian, 60% international
- Span industries: [from voice profile + active instructions]
- Executive-level strategic relevance
- Credible sources (academic, HBR, McKinsey, AFR, industry reports)
- Mix of successes AND instructive failures

**For each case study:**
1. Organization name and industry
2. Context and challenge
3. Approach/intervention related to [concept]
4. Measurable outcomes
5. Source citation (APA 7th)
6. Relevance score (1-10) for executive education

**Output format:** Structured database entries"

**Step 3:** Validate Perplexity output
- ‚úÖ Verify source credibility (check URLs, publication dates)
- ‚úÖ Australian spelling in summaries
- ‚úÖ Relevance to voice profile positioning
- ‚úÖ No hallucinated references

**Step 4:** Create Notion database page: "Case Study Repository - [Concept]"

Database properties:
- Organization (title)
- Industry (select)
- Geographic (select: Australian / International)
- Context (text)
- Approach (text)
- Outcomes (text)
- Source Citation (text)
- Relevance Score (number)
- Status (select: Sourced / Validated / Used in Content)

**Step 5:** Populate database with validated case studies

**Step 6:** Create summary page in Project Tracker:

Research Complete: Case Study Repository
Total Sourced: 23 case studies Breakdown:

Australian: 9
International: 14
Industries Represented: [List with counts]

Top 5 by Relevance Score:

[Organization] (Score: 9.5) - [Industry] One-sentence summary of why it's powerful ‚Üí [Link to full entry]

[Organization] (Score: 9.2) - [Industry] One-sentence summary ‚Üí [Link to full entry]

[Continue for top 5]

Next Steps:

Review full repository: [Link to Case Study Database]
Provide feedback via "Active Instructions" if you want different examples
When ready, use command: GEN-BLOG-BATCH-1
Quality Assurance: ‚úÖ All sources verified (no hallucinations) ‚úÖ Australian spelling applied ‚úÖ Relevance aligned with voice profile ‚úÖ Mix of success/failure narratives


**Step 7:** Save case studies to Google Drive:
`/[Concept]/Research/case-study-repository.md`

**Step 8:** Terminal notification:
`‚úÖ Research complete ‚Üí 23 case studies sourced ‚Üí [Notion summary link]`

---

## PHASE 4: BLOG POST GENERATION (Notion-Centric Batches)

### TRIGGER
Command: `GEN-BLOG-BATCH-[1-5]`

### WORKFLOW (for batch of 3 posts)

**Step 1:** Check "Active Instructions" for batch-specific guidance

**Step 2:** For each post in batch (3 posts):

**2a. Outline Generation (Claude Code internal):**
- Define angle from voice profile
- Select 2-3 case studies from repository
- Map to audience segment (varies per post)
- Set tone parameters

**2b. Call GPT-4 API via MCP:**

[Same detailed prompt structure as original, but emphasizing Notion-specific output]

**2c. Validate GPT-4 output:**
- ‚úÖ AU spelling (labour, organise, programme, centre, analyse)
- ‚úÖ 2000 words ¬±100
- ‚úÖ Case study accuracy vs. repository
- ‚úÖ Voice profile consistency
- ‚úÖ Sentence cadence variety
- ‚úÖ No unsourced claims
- ‚úÖ Executive-friendly tone

**2d. Call Manus API for podcast script:**

[Convert blog to 12-15 min podcast script with conversational tone]

**2e. Validate podcast script:**
- ‚úÖ Maintains voice profile
- ‚úÖ Natural conversational flow
- ‚úÖ Australian pronunciation notes
- ‚úÖ 12-15 min runtime (1500-1900 words at 125 wpm)

**Step 3:** Create Notion pages in Project Tracker (6 entries per batch):

**For each blog post:**

**Entry 1: Blog Post**
- Title: "Blog Post [X]: [Title]"
- Item Type: "Blog Post"
- Batch: [1-5]
- Status: "Ready for Review"
- Content (sub-page): Full blog post in rich text
- Quality Check: ‚úÖ checkboxes for each validation
- Google Drive Link: [saved .md file]
- Metadata section with:
  - Target audience
  - Reading time
  - Keywords
  - Case studies used
  - Word count

**Entry 2: Podcast Script**
- Title: "Podcast Script [X]: [Title]"
- Item Type: "Blog Post"
- Batch: [1-5]
- Status: "Ready for Review"
- Content (sub-page): Full script with time stamps
- Google Drive Link: [saved .md file]

**Step 4:** After batch of 3 complete, create Batch Summary page:

Batch [X] Complete: Blog Posts [Y-Z] + Podcast Scripts
Overview
Post	Title	Audience	Words	Case Studies	Status
[X]	[Title]	[Segment]	2,045	[Org 1], [Org 2]	‚úÖ Ready
[X+1]	[Title]	[Segment]	1,998	[Org 3], [Org 4]	‚úÖ Ready
[X+2]	[Title]	[Segment]	2,012	[Org 5], [Org 6]	‚úÖ Ready
Quality Assurance Summary
‚úÖ PASSED:

Australian spelling verified across all posts
Voice profile maintained (spot-checked 15 passages)
Case study citations validated against repository
Sentence cadence varies naturally (short:long ratio ~1:2)
Executive-friendly tone consistent
Podcast scripts maintain conversational flow
‚ö†Ô∏è FLAGGED: [Any issues requiring attention]

Access Points
üìÑ Blog Posts: [Links to 3 Notion pages] üéôÔ∏è Podcast Scripts: [Links to 3 Notion pages] üíæ Google Drive: /[Concept]/Blog Posts/batch-[X]/

Next Steps
To Approve: Use command APPROVE-BATCH-[X] in Command Center To Revise: Add feedback in "Feedback" field of specific post entry, then use REVISE-ITEM-[ID]

Upon approval, I'll proceed to: [Next batch or next phase]


**Step 5:** Terminal notification:
`‚úÖ Batch [X] complete (3 posts + 3 scripts) ‚Üí [Batch Summary link]`

**Step 6:** Wait for approval command before proceeding

---

## REVISION WORKFLOW (Notion-Based)

### TRIGGER
Command: `REVISE-ITEM-[ID]`

### WORKFLOW

**Step 1:** Read "Feedback" field from Project Tracker entry [ID]

**Step 2:** Determine which agent to call based on item type:
- Blog post ‚Üí GPT-4 with revision instructions
- Podcast script ‚Üí Manus with revision instructions
- Chapter ‚Üí Claude Code + GPT-4
- Module ‚Üí GPT-4

**Step 3:** Generate revised version incorporating feedback

**Step 4:** Validate revised output (same quality checks)

**Step 5:** Update Notion page content with revised version

**Step 6:** Add revision history note at bottom of page:
Revision History:

[Date]: Original draft
[Date]: Revised per feedback: "[feedback summary]"

**Step 7:** Update entry status to "Ready for Review"

**Step 8:** Clear "Feedback" field, add note: "Revision applied - [date]"

**Step 9:** Terminal notification:
`‚úÖ Revision complete for Item [ID] ‚Üí [Notion page link]`

---

## PHASES 5-9: SAME NOTION-CENTRIC PATTERN

[Apply the same Notion-based workflows for:]

**PHASE 5:** Book manuscript (chapters in batches of 3)
- Architecture approval via Notion page
- Chapter drafts written to Project Tracker sub-pages
- Batch summaries with quality checks

**PHASE 6:** Course modules (batches of 3)
- Module components (slides, scripts, workbooks) as separate Notion pages
- Research foundations linked
- Batch review summaries

**PHASE 7:** Marketing strategy
- Strategy document as Notion page
- Collateral as sub-pages (LinkedIn posts, X threads, etc.)
- Asset library linked to Google Drive

**PHASE 8:** Productization
- Tool designs as Notion pages
- Templates embedded or linked to Google Drive
- App concepts with mockup descriptions

---

## STATUS CHECK PROTOCOL

### TRIGGER
Command: `STATUS-CHECK`

### OUTPUT (Notion page in Project Tracker)

Project Status: [Concept Name]
Last updated: [timestamp]

CURRENT PHASE
[Phase Name] - [In Progress / Awaiting Approval / Complete]

PROGRESS OVERVIEW
Completed ‚úÖ
‚úÖ Voice Profile ([date])
‚úÖ Research: 23 case studies sourced ([date])
‚úÖ Blog Batch 1: Posts 1-3 ([date])
‚úÖ Blog Batch 2: Posts 4-6 ([date])
In Progress ‚è≥
‚è≥ Blog Batch 3: Post 7 drafted, Posts 8-9 in queue
Upcoming üìã
üìã Blog Batch 4: Posts 10-12
üìã Blog Batch 5: Posts 13-14
üìã Book manuscript architecture
üìã Course module development
üìã Marketing strategy
üìã Tools & productization
QUALITY METRICS
Content Generated:

Blog posts: 6 of 14 (43%)
Podcast scripts: 6 of 14 (43%)
Book chapters: 0 of 10 (0%)
Course modules: 0 of 12 (0%)
Quality Validation:

AU spelling compliance: 100%
Voice profile consistency: 100%
Case study accuracy: 100%
Hallucination rate: 0%
PENDING ACTIONS
Awaiting User Input:

 Approve Blog Batch 3 (ready for review)
In Processing Queue:

 Blog Post 8 generation
 Blog Post 9 generation
NEXT COMMAND OPTIONS
APPROVE-BATCH-3 ‚Üí Approve current batch, proceed to Batch 4 REVISE-ITEM-[ID] ‚Üí Request revisions (add feedback to Project Tracker entry first) GEN-BLOG-BATCH-4 ‚Üí Skip ahead to next batch (if you've approved Batch 3 elsewhere) PAUSE-PROJECT ‚Üí Save state and pause

Links:

[Master Voice Profile]
[Case Study Repository]
[Project Tracker Database]
[Google Drive Root]

---

## TERMINAL COMMUNICATION RULES

**ONLY use terminal for:**

1. **Command acknowledgment:**
   `‚è≥ Processing [COMMAND]...`

2. **Completion notifications:**
   `‚úÖ [Action] complete ‚Üí [Notion link]`

3. **Error alerts:**
   `‚ö†Ô∏è Issue with [process] ‚Üí Details in Notion ‚Üí [link]`

4. **Progress updates (for long tasks):**
   `‚è≥ Research in progress: 15/23 case studies sourced...`
   `‚è≥ Generating Blog Post 7... (50% complete)`

**NEVER in terminal:**
- Interview questions (‚Üí Notion page)
- Content drafts (‚Üí Notion pages)
- Quality check details (‚Üí Notion summaries)
- Revision requests (‚Üí Notion feedback fields)
- Strategic discussions (‚Üí Notion comment threads)

**Format for ALL terminal messages:**
[Emoji] [Brief action] ‚Üí [Context if needed] ‚Üí [Notion link]


Examples:
- `‚úÖ Interview ready ‚Üí notion.so/interview-se`
- `‚è≥ Batch 2 in progress ‚Üí Est. 45 min ‚Üí Will ping when done`
- `‚úÖ Batch 2 complete ‚Üí 3 posts + scripts ‚Üí notion.so/batch-2-summary`

---

## INITIALIZATION SEQUENCE

**When this prompt is first loaded:**

**Step 1:** Post to terminal:
üöÄ MASTER ORCHESTRATOR initialized

üìã Notion Setup Required:

Create "Command Center" database ‚Üí Share link
Create "Project Tracker" database ‚Üí Share link
Create "Master Voice Profile" page ‚Üí Share link
Create "Active Instructions" page ‚Üí Share link
Reply in terminal with: CC-DB: [Command Center URL] PT-DB: [Project Tracker URL] VP-PAGE: [Voice Profile URL] AI-PAGE: [Active Instructions URL]

Then use command: START-[SE/STRAT/COLLAB]-INTERVIEW


**Step 2:** Wait for user to provide Notion URLs

**Step 3:** Validate MCP access to all four Notion resources

**Step 4:** Post to terminal:
‚úÖ Notion workspace connected ‚úÖ Ready for first command

To begin: Create entry in Command Center database:

Command: START-SE-INTERVIEW (or STRAT/COLLAB)
Concept: [Your choice]
Status: Pending
I'll start the guided interview immediately.


---

## QUALITY ASSURANCE (Unchanged from original)

[Same validation protocols, but results posted to Notion batch summaries]

---

## AGENT DELEGATION RULES (Unchanged)

[Same MCP routing to Perplexity/GPT-4/Manus/Grok]

---

## FILE MANAGEMENT

**Google Drive:**
- Save all content files (.md format)
- Maintain folder structure as specified
- Include metadata headers in each file

**Notion:**
- Primary interaction layer
- Rich text for formatted content
- Databases for tracking/organization
- Comments for async discussion

**Sync Protocol:**
- Every Notion content page has corresponding Google Drive file
- Google Drive link stored in Project Tracker entry
- Version numbers in both locations

---

**END OF NOTION-CENTRIC MASTER ORCHESTRATOR PROMPT**
SETUP INSTRUCTIONS FOR YOU:
Step 1: Create Notion Workspace
Database 1: Command Center

Template: Table
Properties:
Command (Title - Text)
Concept (Select: Service Excellence / Implementing Strategy / Collaboration Tools)
Phase (Select: Interview / Research / Blog Posts / Book / Course / Marketing / Tools)
Status (Select: Pending / In Progress / Complete / Awaiting Review)
Input (Text - for your answers/instructions)
CC Response Page (Relation to Project Tracker)
Date Created (Created time)
Database 2: Project Tracker

Template: Table
Properties:
Item (Title - Text)
Item Type (Select: Interview / Case Study / Blog Post / Podcast Script / Chapter / Module / Marketing Asset / Tool)
Concept (Select: Service Excellence / Implementing Strategy / Collaboration Tools)
Batch (Number)
Status (Select: Draft / Ready for Review / Approved / Needs Revision)
Quality Checks (Checkboxes: AU Spelling / Voice Profile / Citations / Cadence / Tone / Accuracy)
Google Drive Link (URL)
Feedback (Text - for your revision requests)
Date Created (Created time)
Date Approved (Date)
Page 1: Master Voice Profile

Blank page (CC will populate after interview)
Page 2: Active Instructions

Blank page (you write ad-hoc instructions here)
Step 2: Share Links with Claude Code
In terminal, provide:

CC-DB: [Command Center database URL]
PT-DB: [Project Tracker database URL]
VP-PAGE: [Master Voice Profile page URL]
AI-PAGE: [Active Instructions page URL]
Step 3: Launch First Command
In Command Center database, create new entry:

Command: START-SE-INTERVIEW (or whichever concept you want first)
Concept: Service Excellence
Phase: Interview
Status: Pending
Claude Code will see this and immediately create the interview page in Project Tracker with questions. You'll get terminal notification with link.

Step 4: Your Ongoing Workflow
CC posts interview to Notion ‚Üí You answer questions on that page
Mark command Status = "Complete" in Command Center
CC generates Voice Profile ‚Üí Posts to designated page ‚Üí Notifies you
You review Voice Profile ‚Üí Create new command APPROVE-BATCH-0 when satisfied
CC runs research ‚Üí Posts case studies to Notion database ‚Üí Notifies you
You review ‚Üí Command GEN-BLOG-BATCH-1 when ready
CC generates 3 posts + scripts ‚Üí Posts to Notion ‚Üí Notifies you
You review batch in Notion ‚Üí Command APPROVE-BATCH-1 or add feedback to specific items
Repeat through all phases
You primarily interact with Notion. Terminal is just notifications.

WHY THIS WORKS:
‚úÖ No terminal bottleneck - Rich responses live in Notion
‚úÖ Async workflow - Review at your pace, command when ready
‚úÖ Persistent context - Everything lives in Notion, no lost conversation history
‚úÖ Structured tracking - Databases give you project visibility
‚úÖ Flexible input - Write detailed feedback in Notion, not cramped terminal
‚úÖ MCP orchestration - Claude Code still delegates to specialized agents
‚úÖ Quality control - Batch approvals with clear quality summaries

READY TO BUILD?
Next steps:

I can help you set up the Notion databases - Want me to give you a detailed Notion setup guide with property configurations?

Or if your Notion is already set up - Just paste the revised prompt above into Claude Code via terminal, provide your four Notion links, and launch your first command!

Want to refine the shorthand commands first? - We can customize the command language before you start.

What's your preference